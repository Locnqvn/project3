{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTUR_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd3YrOxM7K2R",
        "outputId": "8c3d6dc8-cf95-422e-f8ff-b4ee2ced4dd3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90CsdU47sr0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b851c51d-1613-483a-a4e7-09625d9b9fa1"
      },
      "source": [
        "!pip install pickle5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.6/dist-packages (0.0.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qBbEz35ve7J"
      },
      "source": [
        "from collections import defaultdict\n",
        "import pickle5 as pickle\n",
        "import numpy as np \n",
        "import argparse\n",
        "import random\n",
        "import time \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import bottleneck as bn\n",
        "import time\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCz7L8Lc3DYd"
      },
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZhGbDy38V9Q"
      },
      "source": [
        "class AdditiveAttention(nn.Module):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 query_vector_dim,\n",
        "                 candidate_vector_dim,\n",
        "                 ):\n",
        "        super(AdditiveAttention, self).__init__()\n",
        "        self.linear = nn.Linear(candidate_vector_dim, query_vector_dim)\n",
        "        self.attention_query_vector = nn.Parameter(\n",
        "            torch.empty(query_vector_dim).uniform_(-0.1, 0.1))\n",
        "        \n",
        "\n",
        "    def forward(self, candidate_vector):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            candidate_vector: batch_size, candidate_size, candidate_vector_dim\n",
        "        Returns:\n",
        "            (shape) batch_size, candidate_vector_dim\n",
        "        \"\"\"\n",
        "        # batch_size, candidate_size, query_vector_dim\n",
        "        temp = torch.tanh(self.linear(candidate_vector))\n",
        "        # batch_size, candidate_size\n",
        "        candidate_weights = F.softmax(torch.matmul(\n",
        "            temp, self.attention_query_vector),\n",
        "                                      dim=1)\n",
        "        \n",
        "        # batch_size, candidate_vector_dim\n",
        "        target = torch.bmm(candidate_weights.unsqueeze(dim=1),\n",
        "                           candidate_vector).squeeze(dim=1)\n",
        "        return target\n",
        "\n",
        "class MovieEncoder(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super(MovieEncoder,self).__init__()\n",
        "        self.config=config\n",
        "        self.title_embedding=nn.Embedding(\n",
        "            self.config.num_items+1,\n",
        "            self.config.title_embed_dim,\n",
        "            padding_idx=0\n",
        "        )\n",
        "        self.title_embedding.weight.data.copy_(torch.from_numpy(config.pre_train_title))\n",
        "        self.title_embedding.requires_grad=config.finetune_title\n",
        "\n",
        "        self.cats=nn.Embedding(\n",
        "            self.config.num_items+1,\n",
        "            self.config.num_cat+1,\n",
        "            # padding_idx=0\n",
        "        )\n",
        "        self.cats.weight.data.copy_(torch.from_numpy(self.config.cats))\n",
        "        self.cats.requires_grad=False\n",
        "\n",
        "        self.cats_embedding=nn.Embedding(\n",
        "            self.config.num_cat+1,\n",
        "            self.config.cat_embed_dim,\n",
        "            padding_idx=0\n",
        "        )\n",
        "        self.mask=nn.Embedding(\n",
        "            self.config.num_cat+1,\n",
        "            self.config.cat_embed_dim,\n",
        "            padding_idx=0\n",
        "        )\n",
        "        self.mask.weight.data.copy_(torch.from_numpy(self.config.masking_cat))\n",
        "        self.mask.requires_grad=False\n",
        "        self.attension=AdditiveAttention(\n",
        "            self.config.cat_embed_dim,\n",
        "            self.config.cat_embed_dim\n",
        "        )\n",
        "    \n",
        "    def forward(self,seq_history):\n",
        "        \"\"\"\n",
        "        imput: batch_size,seq_length\n",
        "        output: batch_size,seq_length,vector_embedding\n",
        "        \"\"\"\n",
        "        # print('size of seq',seq_history.shape)\n",
        "        # print('seq',seq_history)\n",
        "        title_embed=self.title_embedding(seq_history)\n",
        "        cat=self.cats(seq_history)\n",
        "        # print(cat.size())\n",
        "        # print(cat)\n",
        "        cat=cat.type(torch.LongTensor)\n",
        "    \n",
        "        cat=cat.to(self.config.device)\n",
        "        # print(cat.size())\n",
        "        cat_embed=self.cats_embedding(cat)\n",
        "        mask=self.mask(cat)\n",
        "        cat_embed=cat_embed*mask\n",
        "        x,y,z,t=cat_embed.shape\n",
        "\n",
        "        cat_embed=cat_embed.view(x*y,z,t)\n",
        "        cat_embed=self.attension(cat_embed)\n",
        "        cat_embed=cat_embed.view(x,y,t)\n",
        "        \n",
        "        return torch.cat((title_embed.permute(0,2,1),cat_embed.permute(0,2,1)),dim=1).permute(0,2,1)\n",
        "\n",
        "\n",
        "class LSTUR(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(LSTUR, self).__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "                config.hidden_gru_size,\n",
        "                config.hidden_gru_size )\n",
        "            \n",
        "        self.movie_encoder=MovieEncoder(self.config).to(self.config.device)\n",
        " \n",
        "        self.user_embedding = nn.Embedding(\n",
        "            config.num_users+1,\n",
        "            config.hidden_gru_size ,\n",
        "            padding_idx=0)\n",
        " \n",
        "    def forward(self, user, clicked_movies,candidate_movies):\n",
        "        user = F.dropout2d(self.user_embedding(\n",
        "            user.to(self.config.device)).unsqueeze(dim=0),\n",
        "                           p=self.config.masking_probability,\n",
        "                           training=self.training).squeeze(dim=0)\n",
        " \n",
        "        clicked_moives_vector = self.movie_encoder(clicked_movies).permute(1,0,2)\n",
        "        # batch_size, num_filters * 2\n",
        "        \n",
        "        _, last_hidden = self.gru(clicked_moives_vector,\n",
        "                                    user.unsqueeze(dim=0))\n",
        "        user_vector = last_hidden.squeeze(dim=0)\n",
        " \n",
        "        candidate_movies_vector=self.movie_encoder(candidate_movies).permute(1,0,2)\n",
        "        # batch_size, 1 + K\n",
        "        click_probability = torch.bmm(candidate_movies_vector.permute(1,0,2),\n",
        "                                user_vector.unsqueeze(dim=-1)).squeeze(dim=-1)\n",
        "        return click_probability\n",
        " \n",
        "    def get_prediction(self, user, clicked_moives,candidate_movies):\n",
        "        user=self.user_embedding(user)\n",
        "        clicked_moives_vector = self.movie_encoder(clicked_moives).permute(1,0,2)\n",
        "        \n",
        "        # batch_size, num_filters * 2\n",
        "        _, last_hidden = self.gru(clicked_moives_vector,\n",
        "                                    user.unsqueeze(dim=0))\n",
        "        user_vector = last_hidden.squeeze(dim=0)\n",
        "\n",
        "        candidate_movies_vector=self.movie_encoder(candidate_movies).permute(1,0,2)\n",
        "\n",
        "        click_probability = torch.bmm(candidate_movies_vector.permute(1,0,2),\n",
        "                                user_vector.unsqueeze(dim=-1)).squeeze(dim=-1)\n",
        "        return click_probability\n",
        " \n",
        "class LSTUR_for_news:\n",
        "    def __init__(self,config_):\n",
        "        self.config=config_\n",
        "        self.device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        self.net=LSTUR(self.config).to(self.device)\n",
        "        self.optimizer=torch.optim.Adam(self.net.parameters(),lr=1e-4)\n",
        "        self.recall_5=[]\n",
        "        self.recall_10=[]\n",
        "        self.recall_20=[]\n",
        "        self.recall_40=[]\n",
        "        self.recall_30=[]\n",
        "        self.recall_50=[]\n",
        "        self.ndcg_10=[]\n",
        "        self.ndcg_20=[]\n",
        "        self.ndcg_30=[]\n",
        "        self.ndcg_40=[]\n",
        "        self.ndcg_50=[]\n",
        "        \n",
        "\n",
        "    def trainer(self,max_iter):\n",
        "        data_train=DataReader(self.config.path_train,self.config,data_train=True)\n",
        "        data_val=DataReader(self.config.path_val,self.config,data_train=False)\n",
        "        \n",
        "        it=0\n",
        "        old_epoch=0\n",
        "        best_ndcg=0\n",
        "        t=time.time()\n",
        "        while it<max_iter:\n",
        "            self.net.train()\n",
        "            batch_users,batch_seq_history,batch_pos_neg,batch_labels,_=data_train.next_batch()\n",
        "            self.optimizer.zero_grad()\n",
        " \n",
        "            batch_users=torch.from_numpy(batch_users).to(self.device)\n",
        "            batch_seq_history=torch.from_numpy(batch_seq_history).to(self.device)\n",
        "            \n",
        "            batch_pos_neg=torch.from_numpy(batch_pos_neg).to(self.device)\n",
        "            clicked_prob=self.net(batch_users,batch_seq_history,batch_pos_neg)\n",
        "            \n",
        "            loss=self.loss_func(clicked_prob)\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            if(it%300==0):\n",
        "                print('epoch {} : it = {}, loss = {}'.format(old_epoch,it,loss.item()))\n",
        "                # eval_ndcg=self.eval(data_val)\n",
        "                # print('epoch {} : NDCG_50 = {}'.format(old_epoch,eval_ndcg))\n",
        "\n",
        "            if(old_epoch!=data_train.epoch):\n",
        "                print('time train =',time.time()-t,end=' ')\n",
        "                t=time.time()\n",
        "                old_epoch=data_train.epoch\n",
        "                eval_ndcg=self.eval(data_val)\n",
        "                print('epoch {} : NDCG_50 = {}'.format(old_epoch,eval_ndcg))\n",
        "                if(best_ndcg<eval_ndcg):\n",
        "                    best_ndcg=eval_ndcg\n",
        "                    self.save_model(old_epoch,loss.item())       \n",
        "            it+=1\n",
        " \n",
        "    def eval(self,data_val,k=10):\n",
        "        self.net.eval()\n",
        "        list_ndcg_10=[]\n",
        "        list_ndcg_20=[]\n",
        "        list_ndcg_30=[]\n",
        "        list_ndcg_40=[]\n",
        "        list_ndcg_50=[]\n",
        "        \n",
        "        list_recall_5=[]\n",
        "        list_recall_10=[]\n",
        "        list_recall_20=[]\n",
        "        list_recall_30=[]\n",
        "        list_recall_40=[]\n",
        "        list_recall_50=[]\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # get candidate \n",
        "            while True:\n",
        "                batch_users,batch_seq_history,_,batch_labels,candidate=data_val.next_batch()\n",
        "\n",
        "                heldout=np.zeros((self.config.num_candidate,self.config.batch_size),dtype=np.int)\n",
        "                heldout[0]=1\n",
        "                heldout=heldout.T\n",
        "\n",
        "                batch_seq_history=torch.from_numpy(batch_seq_history).to(self.device)\n",
        "                batch_users=torch.from_numpy(np.array(batch_users)).to(self.device)\n",
        "                candidate=torch.from_numpy(np.array(candidate,dtype=np.int)).to(self.device)\n",
        " \n",
        "                x_pred=self.net(batch_users,batch_seq_history,candidate)\n",
        "                x_pred=x_pred.detach().cpu().numpy()\n",
        "                \n",
        "                #list_ndcg_100.append(self.NDCG_binary_at_k_batch(x_pred,heldout,k=100))\n",
        "                list_ndcg_50.append(self.NDCG_binary_at_k_batch(x_pred,heldout,k=50))\n",
        "                list_ndcg_40.append(self.NDCG_binary_at_k_batch(x_pred,heldout,k=40))\n",
        "                list_ndcg_30.append(self.NDCG_binary_at_k_batch(x_pred,heldout,k=30))\n",
        "                list_ndcg_20.append(self.NDCG_binary_at_k_batch(x_pred,heldout,k=20))\n",
        "                list_ndcg_10.append(self.NDCG_binary_at_k_batch(x_pred,heldout,k=10))\n",
        "                list_recall_5.append(self.Recall_K(x_pred,heldout,k=5))\n",
        "                list_recall_10.append(self.Recall_K(x_pred,heldout,k=10))\n",
        "                list_recall_20.append(self.Recall_K(x_pred,heldout,k=20))\n",
        "                list_recall_30.append(self.Recall_K(x_pred,heldout,k=30))\n",
        "                list_recall_40.append(self.Recall_K(x_pred,heldout,k=40))\n",
        "                list_recall_50.append(self.Recall_K(x_pred,heldout,k=50))\n",
        "                if(data_val.epoch==1):\n",
        "                    data_val.epoch=0\n",
        "                    break\n",
        "            \n",
        "            self.recall_5.append(np.mean(list_recall_5))\n",
        "            self.recall_10.append(np.mean(list_recall_10))\n",
        "            self.recall_20.append(np.mean(list_recall_20))\n",
        "            self.recall_30.append(np.mean(list_recall_30))\n",
        "            self.recall_40.append(np.mean(list_recall_40))\n",
        "            self.recall_50.append(np.mean(list_recall_50))\n",
        "            self.ndcg_10.append(np.mean(list_ndcg_10))\n",
        "            self.ndcg_20.append(np.mean(list_ndcg_20))\n",
        "            self.ndcg_30.append(np.mean(list_ndcg_30))\n",
        "            self.ndcg_40.append(np.mean(list_ndcg_40))\n",
        "            self.ndcg_50.append(np.mean(list_ndcg_50))\n",
        "            #self.ndcg_100.append(np.mean(list_ndcg_100))\n",
        "            return np.array(list_ndcg_50).mean()\n",
        "    \n",
        "        \n",
        "    def loss_func(self,batch_prob):\n",
        "        batch_prob=torch.exp(batch_prob)\n",
        "        \n",
        "        pos=batch_prob.T[0]\n",
        "        \n",
        "        sum_pos_neg=torch.sum(batch_prob,axis=1)\n",
        "        loss=pos/sum_pos_neg\n",
        "        \n",
        "        loss=sum(torch.log(loss))\n",
        "        \n",
        "        return -loss\n",
        " \n",
        " \n",
        "    def Recall_K(self,x_pred,heldout_batch,k=100):\n",
        "        n_users = x_pred.shape[0]\n",
        "        idx = bn.argpartition(-x_pred, k, axis=1)\n",
        "        x_pred_binary = np.zeros_like(x_pred, dtype=bool)\n",
        "        x_pred_binary[np.arange(n_users)[:, np.newaxis], idx[:, :k]] = True\n",
        " \n",
        "        x_true_binary = np.array(heldout_batch) > 0\n",
        "        tmp = (np.logical_and(x_true_binary, x_pred_binary).sum(axis=1)).astype(np.float32)\n",
        "        recall = tmp / np.minimum(k, x_true_binary.sum(axis=1))\n",
        "        return np.mean(recall)\n",
        "    \n",
        "    def NDCG_binary_at_k_batch(self,X_pred, heldout_batch, k=100):\n",
        "        heldout_batch=np.array(heldout_batch)\n",
        "        batch_users = X_pred.shape[0]\n",
        "        idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
        "        topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
        "                           idx_topk_part[:, :k]]\n",
        "        idx_part = np.argsort(-topk_part, axis=1)\n",
        "        # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
        "        # topk predicted score\n",
        "        idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
        "        # build the discount template\n",
        "        tp = 1. / np.log2(np.arange(2, k + 2))\n",
        " \n",
        "        DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
        "                             idx_topk] * tp).sum(axis=1)\n",
        "        IDCG = np.array([(tp[:min(int(n), k)]).sum() for n in heldout_batch.sum(axis=1)])\n",
        "        return (DCG / IDCG).mean()\n",
        "    \n",
        "    def save_model(self,epoch,loss):\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.net.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'loss': loss\n",
        "            }, '/content/drive/MyDrive/Project3/save_data_lda.pth')\n",
        "    \n",
        "class DataReader:\n",
        "    def __init__(self,path,config_,data_train=True):\n",
        "        self.config=config_\n",
        "        self.epoch=0\n",
        "        self.batch_id=0\n",
        "        self.users=[]\n",
        "        self.seq_history=[]\n",
        "        self.candidate=[]\n",
        "        self.labels=[]\n",
        "        self.batch_size=self.config.batch_size\n",
        "        self.data_train=data_train\n",
        "        \n",
        "        with open(path,'r') as f:\n",
        "            data=f.read().splitlines()\n",
        "        \n",
        "        for i in range(len(data)):\n",
        "            data[i]=data[i].split()\n",
        " \n",
        "        for i in range(len(data)):\n",
        "            self.users.append(data[i][0])\n",
        "            self.seq_history.append(data[i][1:10])\n",
        "            self.labels.append(data[i][10])\n",
        "            self.candidate.append(data[i][10:])\n",
        "                \n",
        "        self.users=np.array(self.users,dtype=np.int)\n",
        "        self.seq_history=np.array(self.seq_history,dtype=np.int)\n",
        "        self.labels=np.array(self.labels,dtype=np.int)\n",
        "        self.candidate=np.array(self.candidate,dtype=np.int)        \n",
        "        self.n_batch=int(np.ceil(len(data)/self.batch_size))\n",
        "        \n",
        "    def get_negative(self,seq_history,labels):\n",
        "        if(self.data_train==False):\n",
        "            return None\n",
        "        \n",
        "        batch_negative=[]\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            tmp_seq_history=np.array(copy.copy(seq_history[i]))\n",
        "            \n",
        "            tmp_seq_history=list(tmp_seq_history[tmp_seq_history>0])\n",
        "            while True:\n",
        "                item_negative=list(np.random.choice(self.config.num_items,self.config.negative_sample_ratio,replace=False)+1)\n",
        "                if(len(set(tmp_seq_history+item_negative+[labels[i]]))==(len(set(tmp_seq_history))+self.config.negative_sample_ratio+1)):\n",
        "                    batch_negative.append([labels[i]]+item_negative)\n",
        "                    break\n",
        "            \n",
        "        return np.array(batch_negative,dtype=np.int)\n",
        " \n",
        "    def next_batch(self):\n",
        "        if(self.batch_id>=self.n_batch-1):\n",
        "            self.batch_id=0\n",
        "            self.epoch+=1\n",
        "            tmp=list(zip(self.users,self.seq_history,self.labels,self.candidate))\n",
        "            random.shuffle(tmp)\n",
        "            self.users,self.seq_history,self.labels,self.candidate=list(zip(*tmp))\n",
        "            \n",
        "            self.users=np.array(list(self.users),dtype=np.int)\n",
        "            self.seq_history=np.array(list(self.seq_history),dtype=np.int)\n",
        "            self.labels=np.array(list(self.labels),dtype=np.int)\n",
        "            self.candidate=np.array(list(self.candidate),dtype=np.int)\n",
        "                   \n",
        "            \n",
        "        start=self.batch_id*self.batch_size\n",
        "        end=start+self.batch_size\n",
        "        self.batch_id+=1\n",
        "        return self.users[start:end],\\\n",
        "                self.seq_history[start:end],\\\n",
        "                self.get_negative(self.seq_history[start:end],self.labels[start:end]),\\\n",
        "                self.labels[start:end],\\\n",
        "                self.candidate[start:end]\n",
        "        "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DocknbT3Em1"
      },
      "source": [
        "class Config:\n",
        "    def __init__(self,\n",
        "                 path_train=None,\n",
        "                 path_test=None,\n",
        "                 path_val=None,\n",
        "                 batch_size=100,\n",
        "                 title_embed_dim=50,\n",
        "                 cat_embed_dim=540,                 \n",
        "                 hidden_gru_size=590,\n",
        "                 num_users=0,\n",
        "                 num_items=0,\n",
        "                 num_cat=0,\n",
        "                 max_iter=15000,\n",
        "                 negative_sample_ratio=10,\n",
        "                 masking_probability=0.5,\n",
        "                 num_candidate=100,\n",
        "                 mask_cat=None,\n",
        "                 pre_train_title=None,\n",
        "                 cats=None,\n",
        "                 finetune_title=False,\n",
        "                 lr=1e-4,):\n",
        "        self.path_train=path_train\n",
        "        self.path_val=path_val\n",
        "        self.path_test=path_test\n",
        "        self.batch_size=batch_size\n",
        "        self.title_embed_dim=title_embed_dim\n",
        "        self.cat_embed_dim=cat_embed_dim\n",
        "        self.hidden_gru_size=hidden_gru_size\n",
        "        self.num_users=num_users\n",
        "        self.num_items=num_items\n",
        "        self.num_cat=num_cat\n",
        "        self.max_iter=max_iter\n",
        "        self.num_candidate=num_candidate\n",
        "        self.negative_sample_ratio=negative_sample_ratio\n",
        "        self.masking_probability=masking_probability\n",
        "        self.masking_cat=np.array(mask_cat,dtype=np.int)\n",
        "        self.pre_train_title=np.array(pre_train_title)\n",
        "        self.cats=np.array(cats,dtype=np.int)\n",
        "        self.finetune_title=finetune_title\n",
        "        self.device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8Z7vGxyz4_U"
      },
      "source": [
        "def load_data(path):\n",
        "    data=open(path,'rb') \n",
        "    data=pickle.load(data)\n",
        "    data=np.array(list(data.values()))\n",
        "    return data\n",
        "\n",
        "path_train='/content/drive/MyDrive/Project3/data_train.txt'\n",
        "path_val='/content/drive/MyDrive/Project3/data_val.txt'\n",
        "path_test='/content/drive/MyDrive/Project3/data_test.txt'\n",
        "path_title_embed='/content/drive/MyDrive/Project3/movieId2embed.p'\n",
        "path_masking='/content/drive/MyDrive/Project3/cat_masking.p'\n",
        "path_cat='/content/drive/MyDrive/Project3/movieId2cats.p'\n",
        "\n",
        "\n",
        "title_embedding=load_data(path_title_embed)\n",
        "masking=load_data(path_masking)\n",
        "cats=load_data(path_cat)\n",
        "\n",
        "n_items=len(title_embedding)-1\n",
        "n_users=6040"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj70hwfabdY_"
      },
      "source": [
        "config=Config(path_train=path_train,\n",
        "              path_test=path_test,\n",
        "              path_val=path_val,\n",
        "              num_cat=18,\n",
        "              num_users=n_users,\n",
        "              num_items=n_items,\n",
        "              pre_train_title=title_embedding,\n",
        "              mask_cat=masking,\n",
        "              cats=cats)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nestQojUbCDA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76023047-dddf-4436-aec2-6e5076128112"
      },
      "source": [
        "model=LSTUR_for_news(config)\n",
        "model.trainer(max_iter=35000)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 : it = 0, loss = 410.0194396972656\n",
            "epoch 0 : it = 300, loss = 236.35240173339844\n",
            "epoch 0 : it = 600, loss = 235.57308959960938\n",
            "epoch 0 : it = 900, loss = 185.66293334960938\n",
            "epoch 0 : it = 1200, loss = 187.6563262939453\n",
            "epoch 0 : it = 1500, loss = 208.79196166992188\n",
            "epoch 0 : it = 1800, loss = 185.57232666015625\n",
            "epoch 0 : it = 2100, loss = 188.76455688476562\n",
            "epoch 0 : it = 2400, loss = 178.26141357421875\n",
            "epoch 0 : it = 2700, loss = 131.4141845703125\n",
            "epoch 0 : it = 3000, loss = 160.55343627929688\n",
            "epoch 0 : it = 3300, loss = 269.1005554199219\n",
            "epoch 0 : it = 3600, loss = 133.6104736328125\n",
            "epoch 0 : it = 3900, loss = 135.75086975097656\n",
            "epoch 0 : it = 4200, loss = 143.3461151123047\n",
            "epoch 0 : it = 4500, loss = 166.97366333007812\n",
            "epoch 0 : it = 4800, loss = 183.9907684326172\n",
            "epoch 0 : it = 5100, loss = 146.13563537597656\n",
            "epoch 0 : it = 5400, loss = 238.38563537597656\n",
            "epoch 0 : it = 5700, loss = 151.50294494628906\n",
            "epoch 0 : it = 6000, loss = 138.80532836914062\n",
            "epoch 0 : it = 6300, loss = 169.54446411132812\n",
            "epoch 0 : it = 6600, loss = 128.65452575683594\n",
            "epoch 0 : it = 6900, loss = 155.9158477783203\n",
            "epoch 0 : it = 7200, loss = 215.29876708984375\n",
            "time train = 335.40094208717346 epoch 1 : NDCG_50 = 0.31986052005528276\n",
            "epoch 1 : it = 7500, loss = 167.12974548339844\n",
            "epoch 1 : it = 7800, loss = 161.69871520996094\n",
            "epoch 1 : it = 8100, loss = 162.1508026123047\n",
            "epoch 1 : it = 8400, loss = 167.25668334960938\n",
            "epoch 1 : it = 8700, loss = 171.9183807373047\n",
            "epoch 1 : it = 9000, loss = 164.05181884765625\n",
            "epoch 1 : it = 9300, loss = 148.69747924804688\n",
            "epoch 1 : it = 9600, loss = 163.09507751464844\n",
            "epoch 1 : it = 9900, loss = 158.34390258789062\n",
            "epoch 1 : it = 10200, loss = 154.8592987060547\n",
            "epoch 1 : it = 10500, loss = 159.22271728515625\n",
            "epoch 1 : it = 10800, loss = 156.02464294433594\n",
            "epoch 1 : it = 11100, loss = 157.5504913330078\n",
            "epoch 1 : it = 11400, loss = 160.85565185546875\n",
            "epoch 1 : it = 11700, loss = 141.3618621826172\n",
            "epoch 1 : it = 12000, loss = 154.73471069335938\n",
            "epoch 1 : it = 12300, loss = 166.1387939453125\n",
            "epoch 1 : it = 12600, loss = 141.48472595214844\n",
            "epoch 1 : it = 12900, loss = 155.94700622558594\n",
            "epoch 1 : it = 13200, loss = 159.15628051757812\n",
            "epoch 1 : it = 13500, loss = 153.758056640625\n",
            "epoch 1 : it = 13800, loss = 184.73361206054688\n",
            "epoch 1 : it = 14100, loss = 151.1727752685547\n",
            "epoch 1 : it = 14400, loss = 153.3048095703125\n",
            "epoch 1 : it = 14700, loss = 158.60867309570312\n",
            "time train = 378.335129737854 epoch 2 : NDCG_50 = 0.33049962980233333\n",
            "epoch 2 : it = 15000, loss = 138.94529724121094\n",
            "epoch 2 : it = 15300, loss = 167.09727478027344\n",
            "epoch 2 : it = 15600, loss = 141.8893280029297\n",
            "epoch 2 : it = 15900, loss = 141.2167205810547\n",
            "epoch 2 : it = 16200, loss = 143.74632263183594\n",
            "epoch 2 : it = 16500, loss = 157.81488037109375\n",
            "epoch 2 : it = 16800, loss = 149.75567626953125\n",
            "epoch 2 : it = 17100, loss = 155.5870361328125\n",
            "epoch 2 : it = 17400, loss = 150.93063354492188\n",
            "epoch 2 : it = 17700, loss = 157.9757843017578\n",
            "epoch 2 : it = 18000, loss = 136.74655151367188\n",
            "epoch 2 : it = 18300, loss = 141.121337890625\n",
            "epoch 2 : it = 18600, loss = 151.1802520751953\n",
            "epoch 2 : it = 18900, loss = 143.51214599609375\n",
            "epoch 2 : it = 19200, loss = 155.77978515625\n",
            "epoch 2 : it = 19500, loss = 148.7738494873047\n",
            "epoch 2 : it = 19800, loss = 152.98158264160156\n",
            "epoch 2 : it = 20100, loss = 158.34347534179688\n",
            "epoch 2 : it = 20400, loss = 152.67849731445312\n",
            "epoch 2 : it = 20700, loss = 145.14077758789062\n",
            "epoch 2 : it = 21000, loss = 145.73199462890625\n",
            "epoch 2 : it = 21300, loss = 133.53985595703125\n",
            "epoch 2 : it = 21600, loss = 152.86180114746094\n",
            "epoch 2 : it = 21900, loss = 152.10528564453125\n",
            "epoch 2 : it = 22200, loss = 140.24378967285156\n",
            "time train = 377.79232120513916 epoch 3 : NDCG_50 = 0.3530216770420636\n",
            "epoch 3 : it = 22500, loss = 144.892822265625\n",
            "epoch 3 : it = 22800, loss = 148.79635620117188\n",
            "epoch 3 : it = 23100, loss = 154.29994201660156\n",
            "epoch 3 : it = 23400, loss = 142.50830078125\n",
            "epoch 3 : it = 23700, loss = 129.341064453125\n",
            "epoch 3 : it = 24000, loss = 144.5539093017578\n",
            "epoch 3 : it = 24300, loss = 136.18008422851562\n",
            "epoch 3 : it = 24600, loss = 145.92640686035156\n",
            "epoch 3 : it = 24900, loss = 139.64730834960938\n",
            "epoch 3 : it = 25200, loss = 125.80160522460938\n",
            "epoch 3 : it = 25500, loss = 132.89645385742188\n",
            "epoch 3 : it = 25800, loss = 120.84868621826172\n",
            "epoch 3 : it = 26100, loss = 142.6377716064453\n",
            "epoch 3 : it = 26400, loss = 129.89932250976562\n",
            "epoch 3 : it = 26700, loss = 120.60413360595703\n",
            "epoch 3 : it = 27000, loss = 144.21315002441406\n",
            "epoch 3 : it = 27300, loss = 124.40560150146484\n",
            "epoch 3 : it = 27600, loss = 137.18043518066406\n",
            "epoch 3 : it = 27900, loss = 130.78428649902344\n",
            "epoch 3 : it = 28200, loss = 135.12620544433594\n",
            "epoch 3 : it = 28500, loss = 125.42256164550781\n",
            "epoch 3 : it = 28800, loss = 126.73072052001953\n",
            "epoch 3 : it = 29100, loss = 126.17545318603516\n",
            "epoch 3 : it = 29400, loss = 122.29515838623047\n",
            "epoch 3 : it = 29700, loss = 143.91600036621094\n",
            "time train = 376.03933930397034 epoch 4 : NDCG_50 = 0.38737110556328697\n",
            "epoch 4 : it = 30000, loss = 118.24899291992188\n",
            "epoch 4 : it = 30300, loss = 144.54501342773438\n",
            "epoch 4 : it = 30600, loss = 112.94596862792969\n",
            "epoch 4 : it = 30900, loss = 113.33662414550781\n",
            "epoch 4 : it = 31200, loss = 142.05776977539062\n",
            "epoch 4 : it = 31500, loss = 119.70144653320312\n",
            "epoch 4 : it = 31800, loss = 140.2091827392578\n",
            "epoch 4 : it = 32100, loss = 117.74956512451172\n",
            "epoch 4 : it = 32400, loss = 117.99309539794922\n",
            "epoch 4 : it = 32700, loss = 136.3780975341797\n",
            "epoch 4 : it = 33000, loss = 132.0182342529297\n",
            "epoch 4 : it = 33300, loss = 113.8564682006836\n",
            "epoch 4 : it = 33600, loss = 124.61157989501953\n",
            "epoch 4 : it = 33900, loss = 124.3324966430664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-107920f6bbca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLSTUR_for_news\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-ff77425a117d>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(self, max_iter)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mbatch_pos_neg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_pos_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mclicked_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_users\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_seq_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_pos_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclicked_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-ff77425a117d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, user, clicked_movies, candidate_movies)\u001b[0m\n\u001b[1;32m    116\u001b[0m                            training=self.training).squeeze(dim=0)\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mclicked_moives_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclicked_movies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m# batch_size, num_filters * 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-ff77425a117d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq_history)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mcat_embed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mcat_embed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mcat_embed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-ff77425a117d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, candidate_vector)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \"\"\"\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# batch_size, candidate_size, query_vector_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# batch_size, candidate_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         candidate_weights = F.softmax(torch.matmul(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3k6ykCSFPVX"
      },
      "source": [
        "checkpoint=torch.load('/content/drive/MyDrive/Project3/save_data_lda.pth')\n",
        "model.net.load_state_dict(checkpoint['model_state_dict'])\n",
        "# model.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# model.trainer(path_train=config.path_train,\n",
        "#               path_val=config.path_val,\n",
        "#               max_iter=35000,\n",
        "#               k=50)\n",
        "\n",
        "data_test=DataReader(path_test,config,data_train=False)\n",
        "print(model.eval(data_test,k=10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-uM6TL0UEln"
      },
      "source": [
        "data_train=DataReader(path_train,config,data_train=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v7cff0WUL5n",
        "outputId": "f1ddbcb9-2fef-435a-a0cf-d99d24070124"
      },
      "source": [
        "print(data_train.seq_history[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0 3186]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VteL-tFLCa5H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "a71e82a1-feef-4645-f864-3b6c5318d174"
      },
      "source": [
        "kq=[]\n",
        "kq.append(model.recall_5)\n",
        "kq.append(model.recall_10)\n",
        "kq.append(model.recall_20)\n",
        "kq.append(model.recall_30)\n",
        "kq.append(model.recall_40)\n",
        "kq.append(model.recall_50)\n",
        "kq.append(model.ndcg_10)\n",
        "kq.append(model.ndcg_20)\n",
        "kq.append(model.ndcg_30)\n",
        "kq.append(model.ndcg_40)\n",
        "kq.append(model.ndcg_50)\n",
        "#kq.append(model.ndcg_100)\n",
        "\n",
        "print(kq)\n",
        "kq=np.array(kq,dtype=str)\n",
        "for i in range(len(kq)):\n",
        "    kq[i]=' '.join(kq[i])\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.24593647316538886, 0.26413377192982457, 0.30240131578947366, 0.3625328947368421], [0.40306681270536693, 0.42639254385964914, 0.4691995614035087, 0.5362390350877193], [0.6196276013143484, 0.6377412280701754, 0.6709649122807019, 0.7315350877192983], [0.762026286966046, 0.7737938596491228, 0.7949232456140352, 0.8384320175438598], [0.8580284775465499, 0.8619188596491228, 0.8764802631578947, 0.903201754385965], [0.9209090909090909, 0.9205921052631578, 0.9265131578947369, 0.9437390350877193], [0.20503503721730154, 0.2206490757631248, 0.25083760080013606, 0.29534587128142825], [0.2595829311075138, 0.2738707631961871, 0.301774053112967, 0.3447022925976146], [0.28990026913359673, 0.30282508345365194, 0.32818006398094424, 0.36749845873365033], [0.30847775134702105, 0.319877449673898, 0.34396257321912405, 0.38003178121918707], [0.31986052005528276, 0.33049962980233333, 0.3530216770420636, 0.38737110556328697]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-b2f4c9c420c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mkq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/LSTUR/LSTUR_MODEL/kq.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/LSTUR/LSTUR_MODEL/kq.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2iQrDlsrLE_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}